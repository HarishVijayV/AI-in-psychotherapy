{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25eeb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haris\\anaconda3\\envs\\torch_gpu\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ü§ñ ENCODER-ONLY MODELS FOR TEXT CLASSIFICATION\n",
      "================================================================================\n",
      "\n",
      "üíª Using device: cuda\n",
      "   GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "\n",
      "üìÇ Loading data...\n",
      "‚úÖ Total samples: 494\n",
      "‚úÖ Class distribution: Counter({'positive': 254, 'negative': 133, 'neutral': 107})\n",
      "‚úÖ Number of classes: 3\n",
      "‚úÖ Classes: ['negative' 'neutral' 'positive']\n",
      "\n",
      "================================================================================\n",
      "üìä Train-Validation-Test Split (70-10-20)\n",
      "================================================================================\n",
      "‚úÖ Training: 345 (69.8%)\n",
      "‚úÖ Validation: 50 (10.1%)\n",
      "‚úÖ Test: 99 (20.0%)\n",
      "\n",
      "================================================================================\n",
      "ü§ñ ENCODER-ONLY MODELS TO EVALUATE\n",
      "================================================================================\n",
      "\n",
      "üìã Selected Models:\n",
      "   1. bert-base-multilingual-cased\n",
      "   2. xlm-roberta-base\n",
      "   3. google/muril-base-cased\n",
      "   4. ai4bharat/indic-bert\n",
      "   5. distilbert-base-multilingual-cased\n",
      "\n",
      "================================================================================\n",
      "‚öôÔ∏è HYPERPARAMETERS\n",
      "================================================================================\n",
      "\n",
      "üìä Configuration:\n",
      "   learning_rate: 2e-05\n",
      "   batch_size: 16\n",
      "   num_epochs: 5\n",
      "   warmup_ratio: 0.1\n",
      "   weight_decay: 0.01\n",
      "   max_length: 128\n",
      "\n",
      "================================================================================\n",
      "üöÄ STARTING TRAINING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: bert-base-multilingual-cased\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.007129</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.911592</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.497908</td>\n",
       "      <td>0.553913</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.796506</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.570471</td>\n",
       "      <td>0.565758</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>0.762303</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.666130</td>\n",
       "      <td>0.671037</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>0.740013</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.686509</td>\n",
       "      <td>0.719826</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 1.02 minutes\n",
      "\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 70.00%\n",
      "   F1 Score: 0.6865\n",
      "   Precision: 0.7198\n",
      "   Recall: 0.7000\n",
      "\n",
      "üéØ Evaluating on Test Set...\n",
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 69.70%\n",
      "   F1 Score: 0.6976\n",
      "   Precision: 0.7001\n",
      "   Recall: 0.6970\n",
      "‚úÖ Saved: bert-base-multilingual-cased_confusion_matrix.png\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.7083    0.6296    0.6667        27\n",
      "     neutral     0.5217    0.5714    0.5455        21\n",
      "    positive     0.7692    0.7843    0.7767        51\n",
      "\n",
      "    accuracy                         0.6970        99\n",
      "   macro avg     0.6664    0.6618    0.6629        99\n",
      "weighted avg     0.7001    0.6970    0.6976        99\n",
      "\n",
      "‚úÖ Saved: bert-base-multilingual-cased_predictions.xlsx\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: xlm-roberta-base\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 66/110 00:50 < 00:34, 1.28 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.017393</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.982314</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.046200</td>\n",
       "      <td>0.987358</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 0.85 minutes\n",
      "\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 52.00%\n",
      "   F1 Score: 0.3558\n",
      "   Precision: 0.2704\n",
      "   Recall: 0.5200\n",
      "\n",
      "üéØ Evaluating on Test Set...\n",
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 51.52%\n",
      "   F1 Score: 0.3503\n",
      "   Precision: 0.2654\n",
      "   Recall: 0.5152\n",
      "‚úÖ Saved: xlm-roberta-base_confusion_matrix.png\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.0000    0.0000    0.0000        27\n",
      "     neutral     0.0000    0.0000    0.0000        21\n",
      "    positive     0.5152    1.0000    0.6800        51\n",
      "\n",
      "    accuracy                         0.5152        99\n",
      "   macro avg     0.1717    0.3333    0.2267        99\n",
      "weighted avg     0.2654    0.5152    0.3503        99\n",
      "\n",
      "‚úÖ Saved: xlm-roberta-base_predictions.xlsx\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: google/muril-base-cased\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 66/110 02:43 < 01:52, 0.39 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.089160</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.068779</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.086600</td>\n",
       "      <td>1.059355</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 2.78 minutes\n",
      "\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 52.00%\n",
      "   F1 Score: 0.3558\n",
      "   Precision: 0.2704\n",
      "   Recall: 0.5200\n",
      "\n",
      "üéØ Evaluating on Test Set...\n",
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 51.52%\n",
      "   F1 Score: 0.3503\n",
      "   Precision: 0.2654\n",
      "   Recall: 0.5152\n",
      "‚úÖ Saved: google_muril-base-cased_confusion_matrix.png\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.0000    0.0000    0.0000        27\n",
      "     neutral     0.0000    0.0000    0.0000        21\n",
      "    positive     0.5152    1.0000    0.6800        51\n",
      "\n",
      "    accuracy                         0.5152        99\n",
      "   macro avg     0.1717    0.3333    0.2267        99\n",
      "weighted avg     0.2654    0.5152    0.3503        99\n",
      "\n",
      "‚úÖ Saved: google_muril-base-cased_predictions.xlsx\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: ai4bharat/indic-bert\n",
      "================================================================================\n",
      "‚ùå Error loading ai4bharat/indic-bert: Converting from SentencePiece and Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: distilbert-base-multilingual-cased\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è≥ Training started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 01:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.022412</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.964058</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.013100</td>\n",
       "      <td>0.893005</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.542485</td>\n",
       "      <td>0.677273</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.013100</td>\n",
       "      <td>0.842720</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.635138</td>\n",
       "      <td>0.642996</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.822971</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.650450</td>\n",
       "      <td>0.696571</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 1.10 minutes\n",
      "\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 68.00%\n",
      "   F1 Score: 0.6505\n",
      "   Precision: 0.6966\n",
      "   Recall: 0.6800\n",
      "\n",
      "üéØ Evaluating on Test Set...\n",
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 67.68%\n",
      "   F1 Score: 0.6606\n",
      "   Precision: 0.6761\n",
      "   Recall: 0.6768\n",
      "‚úÖ Saved: distilbert-base-multilingual-cased_confusion_matrix.png\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.6818    0.5556    0.6122        27\n",
      "     neutral     0.6667    0.3810    0.4848        21\n",
      "    positive     0.6769    0.8627    0.7586        51\n",
      "\n",
      "    accuracy                         0.6768        99\n",
      "   macro avg     0.6751    0.5998    0.6186        99\n",
      "weighted avg     0.6761    0.6768    0.6606        99\n",
      "\n",
      "‚úÖ Saved: distilbert-base-multilingual-cased_predictions.xlsx\n",
      "\n",
      "================================================================================\n",
      "üìä FINAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Saved: encoder_models_results.xlsx\n",
      "\n",
      "üèÜ Model Rankings (by Test F1):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "1. bert-base-multilingual-cased\n",
      "   Test Acc: 69.70% | F1: 0.6976\n",
      "   Val Acc: 70.00% | F1: 0.6865\n",
      "   Training Time: 1.02 min\n",
      "\n",
      "4. distilbert-base-multilingual-cased\n",
      "   Test Acc: 67.68% | F1: 0.6606\n",
      "   Val Acc: 68.00% | F1: 0.6505\n",
      "   Training Time: 1.10 min\n",
      "\n",
      "2. xlm-roberta-base\n",
      "   Test Acc: 51.52% | F1: 0.3503\n",
      "   Val Acc: 52.00% | F1: 0.3558\n",
      "   Training Time: 0.85 min\n",
      "\n",
      "3. muril-base-cased\n",
      "   Test Acc: 51.52% | F1: 0.3503\n",
      "   Val Acc: 52.00% | F1: 0.3558\n",
      "   Training Time: 2.78 min\n",
      "\n",
      "‚úÖ Saved: models_comparison.png\n",
      "\n",
      "================================================================================\n",
      "ü•á BEST MODEL: bert-base-multilingual-cased\n",
      "================================================================================\n",
      "   Test Accuracy: 69.70%\n",
      "   Test F1: 0.6976\n",
      "   Training Time: 1.02 minutes\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PIPELINE COMPLETED!\n",
      "================================================================================\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   ‚Ä¢ encoder_models_results.xlsx - All results\n",
      "   ‚Ä¢ models_comparison.png - Visual comparison\n",
      "   ‚Ä¢ [model]_confusion_matrix.png - Per-model confusion matrices\n",
      "   ‚Ä¢ [model]_predictions.xlsx - Per-model predictions\n",
      "\n",
      "üí° Tips to Improve Performance:\n",
      "   1. Increase epochs (try 8-10)\n",
      "   2. Try learning rate 3e-5 or 5e-5\n",
      "   3. Use class weights if imbalanced\n",
      "   4. Add data augmentation (back-translation, paraphrasing)\n",
      "   5. Try ensemble of top 3 models\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, \n",
    "    recall_score, classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ ENCODER-ONLY MODELS FOR TEXT CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nüíª Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüìÇ Loading data...\")\n",
    "df = pd.read_excel(\"labels_sentences_FINAL_ROUND2.xlsx\")\n",
    "X = df['sentences_clean'].values\n",
    "y = df['labels'].values\n",
    "\n",
    "print(f\"‚úÖ Total samples: {len(df)}\")\n",
    "print(f\"‚úÖ Class distribution: {Counter(y)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"‚úÖ Number of classes: {num_labels}\")\n",
    "print(f\"‚úÖ Classes: {label_encoder.classes_}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. TRAIN-VAL-TEST SPLIT (70-10-20)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä Train-Validation-Test Split (70-10-20)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.20, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Training: {len(X_train)} ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Validation: {len(X_val)} ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Test: {len(X_test)} ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. DATASET CLASS\n",
    "# ============================================================================\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# 4. ENCODER-ONLY MODELS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ü§ñ ENCODER-ONLY MODELS TO EVALUATE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "models_to_train = [\n",
    "    \"bert-base-multilingual-cased\",  # mBERT\n",
    "    \"xlm-roberta-base\",              # XLM-R\n",
    "    \"google/muril-base-cased\",       # MURIL\n",
    "    \"ai4bharat/indic-bert\",          # IndicBERT\n",
    "    \"distilbert-base-multilingual-cased\",  # DistilmBERT (faster)\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Selected Models:\")\n",
    "for i, model in enumerate(models_to_train, 1):\n",
    "    print(f\"   {i}. {model}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. OPTIMAL HYPERPARAMETERS (based on NLP best practices)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚öôÔ∏è HYPERPARAMETERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 5,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_length\": 128\n",
    "}\n",
    "\n",
    "print(\"\\nüìä Configuration:\")\n",
    "for param, value in config.items():\n",
    "    print(f\"   {param}: {value}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. METRICS FUNCTION\n",
    "# ============================================================================\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 7. TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "def train_and_evaluate(model_name, config):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üèãÔ∏è Training: {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {model_name}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TextDataset(X_train, y_train, tokenizer, config['max_length'])\n",
    "    val_dataset = TextDataset(X_val, y_val, tokenizer, config['max_length'])\n",
    "    test_dataset = TextDataset(X_test, y_test, tokenizer, config['max_length'])\n",
    "    \n",
    "    # Output directory\n",
    "    output_dir = f\"./results/{model_name.replace('/', '_')}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=config['num_epochs'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=config['batch_size'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        warmup_ratio=config['warmup_ratio'],\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=42,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(\"\\n‚è≥ Training started...\")\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Validation metrics\n",
    "    val_metrics = trainer.evaluate()\n",
    "    print(f\"\\n‚úÖ Training completed in {train_time/60:.2f} minutes\")\n",
    "    print(f\"\\nüìä Validation Metrics:\")\n",
    "    print(f\"   Accuracy: {val_metrics['eval_accuracy']*100:.2f}%\")\n",
    "    print(f\"   F1 Score: {val_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"   Precision: {val_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"   Recall: {val_metrics['eval_recall']:.4f}\")\n",
    "    \n",
    "    # Test set evaluation\n",
    "    print(f\"\\nüéØ Evaluating on Test Set...\")\n",
    "    test_metrics = trainer.evaluate(test_dataset)\n",
    "    print(f\"\\nüìä Test Set Performance:\")\n",
    "    print(f\"   Accuracy: {test_metrics['eval_accuracy']*100:.2f}%\")\n",
    "    print(f\"   F1 Score: {test_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"   Precision: {test_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"   Recall: {test_metrics['eval_recall']:.4f}\")\n",
    "    \n",
    "    # Predictions\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_pred = predictions.predictions.argmax(-1)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=label_encoder.classes_,\n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title(f'Confusion Matrix - {model_name.split(\"/\")[-1]}\\n'\n",
    "              f'Test Accuracy: {test_metrics[\"eval_accuracy\"]*100:.2f}%',\n",
    "              fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    cm_file = f'{model_name.replace(\"/\", \"_\")}_confusion_matrix.png'\n",
    "    plt.savefig(cm_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {cm_file}\")\n",
    "    \n",
    "    # Classification Report\n",
    "    print(f\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, \n",
    "                               target_names=label_encoder.classes_,\n",
    "                               digits=4))\n",
    "    \n",
    "    # Save predictions\n",
    "    pred_file = f'{model_name.replace(\"/\", \"_\")}_predictions.xlsx'\n",
    "    test_pred_df = pd.DataFrame({\n",
    "        'sentence': X_test,\n",
    "        'true_label': label_encoder.inverse_transform(y_test),\n",
    "        'predicted_label': label_encoder.inverse_transform(y_pred),\n",
    "        'correct': y_test == y_pred\n",
    "    })\n",
    "    test_pred_df.to_excel(pred_file, index=False)\n",
    "    print(f\"‚úÖ Saved: {pred_file}\")\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'val_accuracy': val_metrics['eval_accuracy'],\n",
    "        'val_f1': val_metrics['eval_f1'],\n",
    "        'val_precision': val_metrics['eval_precision'],\n",
    "        'val_recall': val_metrics['eval_recall'],\n",
    "        'test_accuracy': test_metrics['eval_accuracy'],\n",
    "        'test_f1': test_metrics['eval_f1'],\n",
    "        'test_precision': test_metrics['eval_precision'],\n",
    "        'test_recall': test_metrics['eval_recall'],\n",
    "        'train_time_minutes': train_time / 60\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 8. TRAIN ALL MODELS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üöÄ STARTING TRAINING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name in models_to_train:\n",
    "    try:\n",
    "        result = train_and_evaluate(model_name, config)\n",
    "        if result:\n",
    "            all_results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Failed to train {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# ============================================================================\n",
    "# 9. RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä FINAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df = results_df.sort_values('test_f1', ascending=False)\n",
    "    results_df.to_excel('encoder_models_results.xlsx', index=False)\n",
    "    print(\"\\n‚úÖ Saved: encoder_models_results.xlsx\")\n",
    "    \n",
    "    print(\"\\nüèÜ Model Rankings (by Test F1):\")\n",
    "    print(\"-\" * 80)\n",
    "    for idx, row in results_df.iterrows():\n",
    "        print(f\"\\n{idx + 1}. {row['model_name'].split('/')[-1]}\")\n",
    "        print(f\"   Test Acc: {row['test_accuracy']*100:.2f}% | F1: {row['test_f1']:.4f}\")\n",
    "        print(f\"   Val Acc: {row['val_accuracy']*100:.2f}% | F1: {row['val_f1']:.4f}\")\n",
    "        print(f\"   Training Time: {row['train_time_minutes']:.2f} min\")\n",
    "    \n",
    "    # Comparison plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    x = np.arange(len(results_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, results_df['val_f1'], width, \n",
    "            label='Validation F1', alpha=0.8, color='skyblue')\n",
    "    plt.bar(x + width/2, results_df['test_f1'], width, \n",
    "            label='Test F1', alpha=0.8, color='coral')\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "    plt.title('Encoder-Only Models Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, [name.split('/')[-1] for name in results_df['model_name']], \n",
    "               rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.axhline(y=0.60, color='red', linestyle='--', linewidth=1, \n",
    "                alpha=0.5, label='60% Baseline')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('models_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"\\n‚úÖ Saved: models_comparison.png\")\n",
    "    \n",
    "    # Best model\n",
    "    best_model = results_df.iloc[0]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ü•á BEST MODEL: {best_model['model_name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"   Test Accuracy: {best_model['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"   Test F1: {best_model['test_f1']:.4f}\")\n",
    "    print(f\"   Training Time: {best_model['train_time_minutes']:.2f} minutes\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No models were successfully trained!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ PIPELINE COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(\"   ‚Ä¢ encoder_models_results.xlsx - All results\")\n",
    "print(\"   ‚Ä¢ models_comparison.png - Visual comparison\")\n",
    "print(\"   ‚Ä¢ [model]_confusion_matrix.png - Per-model confusion matrices\")\n",
    "print(\"   ‚Ä¢ [model]_predictions.xlsx - Per-model predictions\")\n",
    "\n",
    "print(\"\\nüí° Tips to Improve Performance:\")\n",
    "print(\"   1. Increase epochs (try 8-10)\")\n",
    "print(\"   2. Try learning rate 3e-5 or 5e-5\")\n",
    "print(\"   3. Use class weights if imbalanced\")\n",
    "print(\"   4. Add data augmentation (back-translation, paraphrasing)\")\n",
    "print(\"   5. Try ensemble of top 3 models\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5294e98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343f455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9f3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7833cd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d615d78f",
   "metadata": {},
   "source": [
    "Try 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4ba86",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e6306c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ü§ñ TRANSFORMER MODELS WITH HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "\n",
      "üíª Using device: cpu\n",
      "\n",
      "üìÇ Loading data...\n",
      "‚úÖ Total samples: 494\n",
      "‚úÖ Class distribution: Counter({'positive': 254, 'negative': 133, 'neutral': 107})\n",
      "‚úÖ Number of classes: 3\n",
      "‚úÖ Classes: ['negative' 'neutral' 'positive']\n",
      "\n",
      "================================================================================\n",
      "üìä Train-Validation-Test Split (70-10-20)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Training set: 345 samples (69.8%)\n",
      "‚úÖ Validation set: 50 samples (10.1%)\n",
      "‚úÖ Test set: 99 samples (20.0%)\n",
      "\n",
      "================================================================================\n",
      "ü§ñ MODELS TO TRAIN\n",
      "================================================================================\n",
      "\n",
      "‚ÑπÔ∏è  Note: Decoder-only models (like GPT) are not ideal for classification tasks.\n",
      "   They're designed for generation. We'll focus on encoder and encoder-decoder models.\n",
      "\n",
      "üìå bert-base-multilingual-cased\n",
      "   Type: Encoder-Only\n",
      "   Description: Multilingual BERT - 104 languages\n",
      "   Parameters: 179M\n",
      "\n",
      "üìå xlm-roberta-base\n",
      "   Type: Encoder-Only\n",
      "   Description: XLM-RoBERTa - Strong multilingual model\n",
      "   Parameters: 279M\n",
      "\n",
      "üìå google/muril-base-cased\n",
      "   Type: Encoder-Only\n",
      "   Description: MURIL - Indian languages specialized\n",
      "   Parameters: 237M\n",
      "\n",
      "üìå ai4bharat/indic-bert\n",
      "   Type: Encoder-Only\n",
      "   Description: IndicBERT - 12 Indian languages\n",
      "   Parameters: 180M\n",
      "\n",
      "üìå google/mt5-small\n",
      "   Type: Encoder-Decoder\n",
      "   Description: Multilingual T5 - Seq2seq architecture\n",
      "   Parameters: 300M\n",
      "\n",
      "================================================================================\n",
      "üîß HYPERPARAMETER SEARCH SPACE\n",
      "================================================================================\n",
      "\n",
      "üìã Hyperparameter Configurations to Test:\n",
      "\n",
      "   Config 1:\n",
      "      learning_rate: 2e-05\n",
      "      batch_size: 16\n",
      "      num_epochs: 3\n",
      "      warmup_ratio: 0.1\n",
      "      weight_decay: 0.01\n",
      "\n",
      "   Config 2:\n",
      "      learning_rate: 3e-05\n",
      "      batch_size: 16\n",
      "      num_epochs: 4\n",
      "      warmup_ratio: 0.1\n",
      "      weight_decay: 0.01\n",
      "\n",
      "   Config 3:\n",
      "      learning_rate: 5e-05\n",
      "      batch_size: 8\n",
      "      num_epochs: 3\n",
      "      warmup_ratio: 0.0\n",
      "      weight_decay: 0.01\n",
      "\n",
      "üî¢ Total configurations per model: 3\n",
      "\n",
      "================================================================================\n",
      "üöÄ STARTING TRAINING PIPELINE\n",
      "================================================================================\n",
      "\n",
      "üìå Training 3 models x 3 configs = 9 total runs\n",
      "\n",
      "‚ÑπÔ∏è  To train all models including IndicBERT and mT5, modify the 'selected_models' list\n",
      "\n",
      "\n",
      "################################################################################\n",
      "MODEL: bert-base-multilingual-cased (Encoder-Only)\n",
      "################################################################################\n",
      "\n",
      "--- Config 1/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: bert-base-multilingual-cased\n",
      "   Config: LR=2e-05, BS=16, Epochs=3\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 06:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.018467</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.009732</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.031500</td>\n",
       "      <td>0.990553</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 6.72 minutes\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 52.00%\n",
      "   F1 Score: 0.3558\n",
      "   Precision: 0.2704\n",
      "   Recall: 0.5200\n",
      "\n",
      "--- Config 2/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: bert-base-multilingual-cased\n",
      "   Config: LR=3e-05, BS=16, Epochs=4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [88/88 09:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.000587</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.841454</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.490868</td>\n",
       "      <td>0.459643</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.958400</td>\n",
       "      <td>0.822307</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.613904</td>\n",
       "      <td>0.627427</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.958400</td>\n",
       "      <td>0.812436</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.661429</td>\n",
       "      <td>0.683743</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 10.12 minutes\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 66.00%\n",
      "   F1 Score: 0.6614\n",
      "   Precision: 0.6837\n",
      "   Recall: 0.6600\n",
      "\n",
      "--- Config 3/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: bert-base-multilingual-cased\n",
      "   Config: LR=5e-05, BS=8, Epochs=3\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 06:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.057137</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.490217</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.024000</td>\n",
       "      <td>0.941716</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.467512</td>\n",
       "      <td>0.456444</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.840700</td>\n",
       "      <td>0.875461</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.581317</td>\n",
       "      <td>0.590265</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 6.56 minutes\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 58.00%\n",
      "   F1 Score: 0.5813\n",
      "   Precision: 0.5903\n",
      "   Recall: 0.5800\n",
      "\n",
      "================================================================================\n",
      "üèÜ BEST CONFIG FOR bert-base-multilingual-cased\n",
      "================================================================================\n",
      "\n",
      "üìä Best Validation F1: 0.6614\n",
      "\n",
      "‚öôÔ∏è Best Hyperparameters:\n",
      "   learning_rate: 3e-05\n",
      "   batch_size: 16\n",
      "   num_epochs: 4\n",
      "   warmup_ratio: 0.1\n",
      "   weight_decay: 0.01\n",
      "\n",
      "üéØ Evaluating on Test Set...\n",
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 66.67%\n",
      "   F1 Score: 0.6722\n",
      "   Precision: 0.6956\n",
      "   Recall: 0.6667\n",
      "\n",
      "‚úÖ Saved: bert-base-multilingual-cased_confusion_matrix.png\n",
      "\n",
      "üìã Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.5312    0.6296    0.5763        27\n",
      "     neutral     0.5926    0.7619    0.6667        21\n",
      "    positive     0.8250    0.6471    0.7253        51\n",
      "\n",
      "    accuracy                         0.6667        99\n",
      "   macro avg     0.6496    0.6795    0.6561        99\n",
      "weighted avg     0.6956    0.6667    0.6722        99\n",
      "\n",
      "‚úÖ Saved: bert-base-multilingual-cased_test_predictions.xlsx\n",
      "\n",
      "################################################################################\n",
      "MODEL: xlm-roberta-base (Encoder-Only)\n",
      "################################################################################\n",
      "\n",
      "--- Config 1/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: xlm-roberta-base\n",
      "   Config: LR=2e-05, BS=16, Epochs=3\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 06:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.014141</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.978922</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>0.951126</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 7.22 minutes\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 52.00%\n",
      "   F1 Score: 0.3558\n",
      "   Precision: 0.2704\n",
      "   Recall: 0.5200\n",
      "\n",
      "--- Config 2/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: xlm-roberta-base\n",
      "   Config: LR=3e-05, BS=16, Epochs=4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/88 06:55 < 02:22, 0.15 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.111409</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.016187</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.059600</td>\n",
       "      <td>1.002424</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 7.19 minutes\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 52.00%\n",
      "   F1 Score: 0.3558\n",
      "   Precision: 0.2704\n",
      "   Recall: 0.5200\n",
      "\n",
      "--- Config 3/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: xlm-roberta-base\n",
      "   Config: LR=5e-05, BS=8, Epochs=3\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='132' max='132' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [132/132 08:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.084824</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.184780</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.066000</td>\n",
       "      <td>0.980138</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.025600</td>\n",
       "      <td>0.953281</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.355789</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed in 8.46 minutes\n",
      "üìä Validation Metrics:\n",
      "   Accuracy: 52.00%\n",
      "   F1 Score: 0.3558\n",
      "   Precision: 0.2704\n",
      "   Recall: 0.5200\n",
      "\n",
      "================================================================================\n",
      "üèÜ BEST CONFIG FOR xlm-roberta-base\n",
      "================================================================================\n",
      "\n",
      "üìä Best Validation F1: 0.3558\n",
      "\n",
      "‚öôÔ∏è Best Hyperparameters:\n",
      "   learning_rate: 2e-05\n",
      "   batch_size: 16\n",
      "   num_epochs: 3\n",
      "   warmup_ratio: 0.1\n",
      "   weight_decay: 0.01\n",
      "\n",
      "üéØ Evaluating on Test Set...\n",
      "\n",
      "üìä Test Set Performance:\n",
      "   Accuracy: 51.52%\n",
      "   F1 Score: 0.3503\n",
      "   Precision: 0.2654\n",
      "   Recall: 0.5152\n",
      "\n",
      "‚úÖ Saved: xlm-roberta-base_confusion_matrix.png\n",
      "\n",
      "üìã Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.0000    0.0000    0.0000        27\n",
      "     neutral     0.0000    0.0000    0.0000        21\n",
      "    positive     0.5152    1.0000    0.6800        51\n",
      "\n",
      "    accuracy                         0.5152        99\n",
      "   macro avg     0.1717    0.3333    0.2267        99\n",
      "weighted avg     0.2654    0.5152    0.3503        99\n",
      "\n",
      "‚úÖ Saved: xlm-roberta-base_test_predictions.xlsx\n",
      "\n",
      "################################################################################\n",
      "MODEL: google/muril-base-cased (Encoder-Only)\n",
      "################################################################################\n",
      "\n",
      "--- Config 1/3 ---\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è Training: google/muril-base-cased\n",
      "   Config: LR=2e-05, BS=16, Epochs=3\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4802514a434650ad5abfc390c49993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  59%|#####9    | 566M/953M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, \n",
    "    recall_score, classification_report, confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import time\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ü§ñ TRANSFORMER MODELS WITH HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nüíª Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\nüìÇ Loading data...\")\n",
    "df = pd.read_excel(\"labels_sentences_FINAL_ROUND2.xlsx\")\n",
    "X = df['sentences_clean'].values\n",
    "y = df['labels'].values\n",
    "\n",
    "print(f\"‚úÖ Total samples: {len(df)}\")\n",
    "print(f\"‚úÖ Class distribution: {Counter(y)}\")\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"‚úÖ Number of classes: {num_labels}\")\n",
    "print(f\"‚úÖ Classes: {label_encoder.classes_}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä Train-Validation-Test Split (70-10-20)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.20, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Second split: 70% train, 10% val from the 80%\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training set: {len(X_train)} samples ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Validation set: {len(X_val)} samples ({len(X_val)/len(df)*100:.1f}%)\")\n",
    "print(f\"‚úÖ Test set: {len(X_test)} samples ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. DEFINE DATASET CLASS\n",
    "# ============================================================================\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DEFINE MODELS TO TRAIN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ü§ñ MODELS TO TRAIN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "models_config = {\n",
    "    # ENCODER-ONLY MODELS (Best for Classification)\n",
    "    \"bert-base-multilingual-cased\": {\n",
    "        \"type\": \"Encoder-Only\",\n",
    "        \"description\": \"Multilingual BERT - 104 languages\",\n",
    "        \"params\": \"179M\"\n",
    "    },\n",
    "    \"xlm-roberta-base\": {\n",
    "        \"type\": \"Encoder-Only\", \n",
    "        \"description\": \"XLM-RoBERTa - Strong multilingual model\",\n",
    "        \"params\": \"279M\"\n",
    "    },\n",
    "    \"google/muril-base-cased\": {\n",
    "        \"type\": \"Encoder-Only\",\n",
    "        \"description\": \"MURIL - Indian languages specialized\",\n",
    "        \"params\": \"237M\"\n",
    "    },\n",
    "    \"ai4bharat/indic-bert\": {\n",
    "        \"type\": \"Encoder-Only\",\n",
    "        \"description\": \"IndicBERT - 12 Indian languages\",\n",
    "        \"params\": \"180M\"\n",
    "    },\n",
    "    \n",
    "    # ENCODER-DECODER MODEL (Good for seq2seq, can be used for classification)\n",
    "    \"google/mt5-small\": {\n",
    "        \"type\": \"Encoder-Decoder\",\n",
    "        \"description\": \"Multilingual T5 - Seq2seq architecture\",\n",
    "        \"params\": \"300M\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n‚ÑπÔ∏è  Note: Decoder-only models (like GPT) are not ideal for classification tasks.\")\n",
    "print(\"   They're designed for generation. We'll focus on encoder and encoder-decoder models.\\n\")\n",
    "\n",
    "for model_name, info in models_config.items():\n",
    "    print(f\"üìå {model_name}\")\n",
    "    print(f\"   Type: {info['type']}\")\n",
    "    print(f\"   Description: {info['description']}\")\n",
    "    print(f\"   Parameters: {info['params']}\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. HYPERPARAMETER GRID\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"üîß HYPERPARAMETER SEARCH SPACE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "hyperparam_configs = [\n",
    "    {\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"num_epochs\": 3,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"num_epochs\": 4,\n",
    "        \"warmup_ratio\": 0.1,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": 5e-5,\n",
    "        \"batch_size\": 8,\n",
    "        \"num_epochs\": 3,\n",
    "        \"warmup_ratio\": 0.0,\n",
    "        \"weight_decay\": 0.01\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"\\nüìã Hyperparameter Configurations to Test:\")\n",
    "for i, config in enumerate(hyperparam_configs, 1):\n",
    "    print(f\"\\n   Config {i}:\")\n",
    "    for param, value in config.items():\n",
    "        print(f\"      {param}: {value}\")\n",
    "\n",
    "print(f\"\\nüî¢ Total configurations per model: {len(hyperparam_configs)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. COMPUTE METRICS FUNCTION\n",
    "# ============================================================================\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    precision = precision_score(labels, preds, average='weighted', zero_division=0)\n",
    "    recall = recall_score(labels, preds, average='weighted', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 7. TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "def train_model(model_name, config, train_dataset, val_dataset, output_dir):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üèãÔ∏è Training: {model_name}\")\n",
    "    print(f\"   Config: LR={config['learning_rate']}, BS={config['batch_size']}, Epochs={config['num_epochs']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=config['num_epochs'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=config['batch_size'],\n",
    "        learning_rate=config['learning_rate'],\n",
    "        weight_decay=config['weight_decay'],\n",
    "        warmup_ratio=config['warmup_ratio'],\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        seed=42,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "    \n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    train_result = trainer.train()\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_metrics = trainer.evaluate()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed in {train_time/60:.2f} minutes\")\n",
    "    print(f\"üìä Validation Metrics:\")\n",
    "    print(f\"   Accuracy: {val_metrics['eval_accuracy']*100:.2f}%\")\n",
    "    print(f\"   F1 Score: {val_metrics['eval_f1']:.4f}\")\n",
    "    print(f\"   Precision: {val_metrics['eval_precision']:.4f}\")\n",
    "    print(f\"   Recall: {val_metrics['eval_recall']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'trainer': trainer,\n",
    "        'tokenizer': tokenizer,\n",
    "        'val_metrics': val_metrics,\n",
    "        'train_time': train_time\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# 8. MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üöÄ STARTING TRAINING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Select top 3 models for faster training (you can train all if needed)\n",
    "selected_models = [\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    \"xlm-roberta-base\",\n",
    "    \"google/muril-base-cased\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüìå Training {len(selected_models)} models x {len(hyperparam_configs)} configs = {len(selected_models) * len(hyperparam_configs)} total runs\")\n",
    "print(\"\\n‚ÑπÔ∏è  To train all models including IndicBERT and mT5, modify the 'selected_models' list\\n\")\n",
    "\n",
    "for model_name in selected_models:\n",
    "    model_info = models_config[model_name]\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"MODEL: {model_name} ({model_info['type']})\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    # Tokenizer for this model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_config = None\n",
    "    best_result = None\n",
    "    \n",
    "    for config_idx, config in enumerate(hyperparam_configs, 1):\n",
    "        print(f\"\\n--- Config {config_idx}/{len(hyperparam_configs)} ---\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "        val_dataset = TextDataset(X_val, y_val, tokenizer)\n",
    "        \n",
    "        # Output directory\n",
    "        output_dir = f\"./results/{model_name.replace('/', '_')}_config{config_idx}\"\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            result = train_model(model_name, config, train_dataset, val_dataset, output_dir)\n",
    "            \n",
    "            # Track best config for this model\n",
    "            if result['val_metrics']['eval_f1'] > best_f1:\n",
    "                best_f1 = result['val_metrics']['eval_f1']\n",
    "                best_config = config\n",
    "                best_result = result\n",
    "            \n",
    "            # Save result\n",
    "            all_results.append({\n",
    "                'model_name': model_name,\n",
    "                'model_type': model_info['type'],\n",
    "                'config_num': config_idx,\n",
    "                'learning_rate': config['learning_rate'],\n",
    "                'batch_size': config['batch_size'],\n",
    "                'num_epochs': config['num_epochs'],\n",
    "                'warmup_ratio': config['warmup_ratio'],\n",
    "                'weight_decay': config['weight_decay'],\n",
    "                'val_accuracy': result['val_metrics']['eval_accuracy'],\n",
    "                'val_f1': result['val_metrics']['eval_f1'],\n",
    "                'val_precision': result['val_metrics']['eval_precision'],\n",
    "                'val_recall': result['val_metrics']['eval_recall'],\n",
    "                'train_time_minutes': result['train_time'] / 60\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error training {model_name} with config {config_idx}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Evaluate best model on test set\n",
    "    if best_result is not None:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üèÜ BEST CONFIG FOR {model_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"\\nüìä Best Validation F1: {best_f1:.4f}\")\n",
    "        print(f\"\\n‚öôÔ∏è Best Hyperparameters:\")\n",
    "        for param, value in best_config.items():\n",
    "            print(f\"   {param}: {value}\")\n",
    "        \n",
    "        # Test set evaluation\n",
    "        print(f\"\\nüéØ Evaluating on Test Set...\")\n",
    "        test_dataset = TextDataset(X_test, y_test, best_result['tokenizer'])\n",
    "        test_metrics = best_result['trainer'].evaluate(test_dataset)\n",
    "        \n",
    "        print(f\"\\nüìä Test Set Performance:\")\n",
    "        print(f\"   Accuracy: {test_metrics['eval_accuracy']*100:.2f}%\")\n",
    "        print(f\"   F1 Score: {test_metrics['eval_f1']:.4f}\")\n",
    "        print(f\"   Precision: {test_metrics['eval_precision']:.4f}\")\n",
    "        print(f\"   Recall: {test_metrics['eval_recall']:.4f}\")\n",
    "        \n",
    "        # Get predictions for confusion matrix\n",
    "        predictions = best_result['trainer'].predict(test_dataset)\n",
    "        y_pred = predictions.predictions.argmax(-1)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=label_encoder.classes_,\n",
    "                    yticklabels=label_encoder.classes_)\n",
    "        plt.title(f'Confusion Matrix - {model_name}\\nTest Accuracy: {test_metrics[\"eval_accuracy\"]*100:.2f}%',\n",
    "                  fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_name.replace(\"/\", \"_\")}_confusion_matrix.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"\\n‚úÖ Saved: {model_name.replace('/', '_')}_confusion_matrix.png\")\n",
    "        \n",
    "        # Classification Report\n",
    "        print(f\"\\nüìã Detailed Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, \n",
    "                                   target_names=label_encoder.classes_,\n",
    "                                   digits=4))\n",
    "        \n",
    "        # Save predictions\n",
    "        test_pred_df = pd.DataFrame({\n",
    "            'sentence': X_test,\n",
    "            'true_label': label_encoder.inverse_transform(y_test),\n",
    "            'predicted_label': label_encoder.inverse_transform(y_pred),\n",
    "            'correct': y_test == y_pred\n",
    "        })\n",
    "        test_pred_df.to_excel(f'{model_name.replace(\"/\", \"_\")}_test_predictions.xlsx', index=False)\n",
    "        print(f\"‚úÖ Saved: {model_name.replace('/', '_')}_test_predictions.xlsx\")\n",
    "        \n",
    "        # Add test metrics to results\n",
    "        all_results[-1].update({\n",
    "            'test_accuracy': test_metrics['eval_accuracy'],\n",
    "            'test_f1': test_metrics['eval_f1'],\n",
    "            'test_precision': test_metrics['eval_precision'],\n",
    "            'test_recall': test_metrics['eval_recall']\n",
    "        })\n",
    "\n",
    "# ============================================================================\n",
    "# 9. SAVE ALL RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üíæ SAVING COMPREHENSIVE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('val_f1', ascending=False)\n",
    "results_df.to_excel('all_models_results.xlsx', index=False)\n",
    "print(\"\\n‚úÖ Saved: all_models_results.xlsx\")\n",
    "\n",
    "# ============================================================================\n",
    "# 10. FINAL SUMMARY & COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ FINAL RESULTS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä Top 5 Model Configurations by Validation F1:\")\n",
    "print(\"-\" * 80)\n",
    "for idx, row in results_df.head(5).iterrows():\n",
    "    print(f\"\\nRank {idx + 1}: {row['model_name']}\")\n",
    "    print(f\"   Type: {row['model_type']}\")\n",
    "    print(f\"   Val F1: {row['val_f1']:.4f} | Val Acc: {row['val_accuracy']*100:.2f}%\")\n",
    "    if 'test_f1' in row and pd.notna(row['test_f1']):\n",
    "        print(f\"   Test F1: {row['test_f1']:.4f} | Test Acc: {row['test_accuracy']*100:.2f}%\")\n",
    "    print(f\"   LR: {row['learning_rate']}, BS: {row['batch_size']}, Epochs: {row['num_epochs']}\")\n",
    "\n",
    "# Visualization: Compare Models\n",
    "if len(results_df) > 0:\n",
    "    # Best result per model\n",
    "    best_per_model = results_df.groupby('model_name').first().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x = np.arange(len(best_per_model))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, best_per_model['val_f1'], width, label='Validation F1', alpha=0.8)\n",
    "    if 'test_f1' in best_per_model.columns:\n",
    "        plt.bar(x + width/2, best_per_model['test_f1'], width, label='Test F1', alpha=0.8)\n",
    "    \n",
    "    plt.xlabel('Model', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.title('Model Comparison - Best Configuration per Model', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, [name.split('/')[-1] for name in best_per_model['model_name']], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.axhline(y=0.85, color='red', linestyle='--', linewidth=2, alpha=0.5, label='85% Target')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"\\n‚úÖ Saved: model_comparison.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ TRANSFORMER TRAINING PIPELINE COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(\"   ‚Ä¢ all_models_results.xlsx - Complete results for all models/configs\")\n",
    "print(\"   ‚Ä¢ model_comparison.png - Visual comparison of models\")\n",
    "print(\"   ‚Ä¢ [model_name]_confusion_matrix.png - Per-model confusion matrices\")\n",
    "print(\"   ‚Ä¢ [model_name]_test_predictions.xlsx - Per-model test predictions\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"   1. Review all_models_results.xlsx to identify best model\")\n",
    "print(\"   2. Analyze confusion matrices for error patterns\")\n",
    "print(\"   3. Fine-tune best model further if needed\")\n",
    "print(\"   4. Deploy best model for production\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ef392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0ee1504",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
